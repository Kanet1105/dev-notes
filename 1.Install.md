# Kubernetes Install Guide

The guide is for Kubernetes version 1.26.1.

## Install and Configure a Container Runtime (containerd)

1. Forwarding IPv4 and letting iptables see bridged traffic:
```
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

# sysctl params required by setup, params persist across reboots
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

# Apply sysctl params without reboot
sudo sysctl --system
```

2. Verify that the br_netfilter, overlay modules are loaded:
```
lsmod | grep br_netfilter
lsmod | grep overlay
```

3. Verify that the net.bridge.bridge-nf-call-iptables, net.bridge.bridge-nf-call-ip6tables, 
net.ipv4.ip_forward system variables are set to 1 in your sysctl config:
```
sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward
```

4. Install containerd:
```
# Remove older versions:
sudo apt remove -y docker docker-engine docker.io containerd runc

# Install prerequisites:
sudo apt update
sudo apt install -y \
    ca-certificates \
    curl \
    gnupg \
    lsb-release
    
# Add Dockerâ€™s official GPG key and set up the repository:
sudo mkdir -m 0755 -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Install the container runtime:
sudo apt update
sudo apt install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
```

5. Configure the systemd cgroup driver:
```
sudo mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml

# To use the systemd cgroup driver in /etc/containerd/config.toml with runc, set
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
  ...
  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
    SystemdCgroup = true
```

6. Restart containerd:
```
sudo systemctl restart containerd
```

## Installing kubeadm, kubelet and kubectl

1. Install using native package management:
```
sudo apt update
sudo apt install -y apt-transport-https ca-certificates curl
```

2. Download the Google Cloud public signing key:
```
sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
```

3. Add the Kubernetes apt repository.
```
echo "deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
```

4. Update apt package index with the new repository and install kubectl:
```
sudo apt update
sudo apt install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
```

## TODO: Set up a High Availability etcd Cluster with kubeadm

Steps to setting up stacked control plane nodes, where etcd nodes are colocated with control plane nodes.
When a node fails, we lose both etcd and the control plane. This can be mitigated by adding more nodes.

## Prerequisites

- Three or more machines that meet kubeadm's minimum requirements for the control-plane nodes. Having an odd number of control plane nodes can help with leader selection in the case of machine or zone failure.
    - including a container runtime, already set up and working
- Three or more machines that meet kubeadm's minimum requirements for the workers
    - including a container runtime, already set up and working
- Full network connectivity between all machines in the cluster (public or private network)
- Superuser privileges on all machines using sudo
    - You can use a different tool; this guide uses sudo in the examples.
- SSH access from one device to all nodes in the system
- kubeadm and kubelet already installed on all machines.

Before you begin, you need:
- Three hosts that can talk to each other over TCP ports 2379 and 2380. This document assumes these default ports. However, they are configurable through the kubeadm config file.
- Each host must have systemd and a bash compatible shell installed.
- Each host must have a container runtime, kubelet, and kubeadm installed.
- Each host should have access to the Kubernetes container image registry (registry.k8s.io) or list/pull the required etcd image using kubeadm config images list/pull. This guide will set up etcd instances as static pods managed by a kubelet.
- Some infrastructure to copy files between hosts. For example ssh and scp can satisfy this requirement.






